{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ct_scan_project_model_3_4_5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zad9CEZUCjyf",
        "colab_type": "code",
        "outputId": "322deb69-e7c3-4043-8a5b-f9d5d57b3801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "import imghdr\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-7u-gy9ynYw",
        "colab_type": "code",
        "outputId": "3f054624-45c9-4a98-db9a-fe82c712a6b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.executing_eagerly()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfBM73zTF6XQ",
        "colab_type": "text"
      },
      "source": [
        "# Using Drive Mounting Instead (Tutorial: https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBlj_N8VYmm1",
        "colab_type": "text"
      },
      "source": [
        "To mount Google Drive:\n",
        "- Run the code below\n",
        "- Click the URL \n",
        "- Sign in & click Allow to get the authorization code\n",
        "- Copy the authorization code and paste it to:\n",
        "  Enter your authorization code: \n",
        "  ____________"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0q0HfRWFLw-",
        "colab_type": "code",
        "outputId": "1e492d5c-90be-4496-ebde-e3333317cb51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zTRfzv3Zwye",
        "colab_type": "text"
      },
      "source": [
        "After mounting, Collab will be connected to your Google Drive\n",
        "Click the File button on the left <-, click 'drive' then 'My Drive', what we need is:\n",
        "- sample_labels.csv file and the ct_scan_img.zip\n",
        "- If it is not there, you can copy it from the Bangkit Group Project Folder\n",
        "- Bangkit Group Project (Assig #5)/DATASET/CT_SCAN/ct_scan_img.zip\"\n",
        "\n",
        "Getting the sample_labels.csv in Colab:\n",
        "- Find the sample_labels.csv file in your drive folder, right-click, and click COPY PATH\n",
        "- Change the path variable below with the path you copied"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHKANobZFZwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/drive/My Drive/Bangkit Group Project (Assig #5)/DATASET/CT_SCAN/sample_labels.csv\"\n",
        "sample_labels = pd.read_csv(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrEdTP5tFwHK",
        "colab_type": "code",
        "outputId": "439d902c-c4b5-429f-dfb6-849cbaf24ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "sample_labels.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Index</th>\n",
              "      <th>Finding Labels</th>\n",
              "      <th>Follow-up #</th>\n",
              "      <th>Patient ID</th>\n",
              "      <th>Patient Age</th>\n",
              "      <th>Patient Gender</th>\n",
              "      <th>View Position</th>\n",
              "      <th>OriginalImageWidth</th>\n",
              "      <th>OriginalImageHeight</th>\n",
              "      <th>OriginalImagePixelSpacing_x</th>\n",
              "      <th>OriginalImagePixelSpacing_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000013_005.png</td>\n",
              "      <td>Emphysema|Infiltration|Pleural_Thickening|Pneu...</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>060Y</td>\n",
              "      <td>M</td>\n",
              "      <td>AP</td>\n",
              "      <td>3056</td>\n",
              "      <td>2544</td>\n",
              "      <td>0.139</td>\n",
              "      <td>0.139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00000013_026.png</td>\n",
              "      <td>Cardiomegaly|Emphysema</td>\n",
              "      <td>26</td>\n",
              "      <td>13</td>\n",
              "      <td>057Y</td>\n",
              "      <td>M</td>\n",
              "      <td>AP</td>\n",
              "      <td>2500</td>\n",
              "      <td>2048</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00000017_001.png</td>\n",
              "      <td>No Finding</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>077Y</td>\n",
              "      <td>M</td>\n",
              "      <td>AP</td>\n",
              "      <td>2500</td>\n",
              "      <td>2048</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00000030_001.png</td>\n",
              "      <td>Atelectasis</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>079Y</td>\n",
              "      <td>M</td>\n",
              "      <td>PA</td>\n",
              "      <td>2992</td>\n",
              "      <td>2991</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00000032_001.png</td>\n",
              "      <td>Cardiomegaly|Edema|Effusion</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>055Y</td>\n",
              "      <td>F</td>\n",
              "      <td>AP</td>\n",
              "      <td>2500</td>\n",
              "      <td>2048</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Image Index  ... OriginalImagePixelSpacing_y\n",
              "0  00000013_005.png  ...                       0.139\n",
              "1  00000013_026.png  ...                       0.168\n",
              "2  00000017_001.png  ...                       0.168\n",
              "3  00000030_001.png  ...                       0.143\n",
              "4  00000032_001.png  ...                       0.168\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4bHmtAo868K",
        "colab_type": "code",
        "outputId": "7d044582-d4f7-4237-c29d-9d7ce13b3836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels = sample_labels['Finding Labels'].tolist()\n",
        "len(labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5606"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qlkBtXJ1aw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#above_100_labels = above_100['Finding Labels'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_DMhoIl1a2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sample_labels = sample_labels_all[sample_labels_all['Finding Labels'] == above_100_labels[0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT3M1hdi1aun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#[for label in above_100_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJZLm_EQZ2WM",
        "colab_type": "text"
      },
      "source": [
        "Getting the CT Scan Images to Colab:\n",
        "- Find the ct_scan_img.zip file in your drive folder (in Colab)\n",
        "- Right-click, then click COPY PATH\n",
        "- Paste the change the path I have, which is: \"/content/drive/My Drive/Bangkit Group Project (Assig #5)/DATASET/CT_SCAN/ct_scan_img.zip\" BELOW, with the one you have.\n",
        "- And then run the !unzip to unzip the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btr5q3XuOVcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/Bangkit Group Project (Assig #5)/DATASET/CT_SCAN/ct_scan_img.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG1skBm3a6j1",
        "colab_type": "text"
      },
      "source": [
        "From the Sample Labels dataframe / table, we get the filename of the images, and make a list out of that called 'image_dir' list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "achW1C03F1NL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_dir = sample_labels['Image Index'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TxKxWmGwVrQ",
        "colab_type": "code",
        "outputId": "404e0b28-8a84-4e87-d0ec-228d4ad2c752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Just checking, carry on~\n",
        "sample_labels[sample_labels['Image Index'] == image_dir[0]]['Finding Labels']"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Emphysema|Infiltration|Pleural_Thickening|Pneu...\n",
              "Name: Finding Labels, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "688b696NwfH0",
        "colab_type": "code",
        "outputId": "0969b7c4-bd39-4cf9-ccca-6f76714408cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(image_dir[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpqIMoUTNwDu",
        "colab_type": "code",
        "outputId": "db66911b-5db9-4741-b2e2-5e3f85b15124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "image_dir[:5]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00000013_005.png',\n",
              " '00000013_026.png',\n",
              " '00000017_001.png',\n",
              " '00000030_001.png',\n",
              " '00000032_001.png']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aya93I2abSnt",
        "colab_type": "text"
      },
      "source": [
        "The RAM available in Google Colab is LIMITED, I believe initially it gives 15 GB.\n",
        "If there is an error of: Colab doesn't have enough RAM, usually it asks if we want MORE RAM, click yes!\n",
        "And it will give us 35 GB.\n",
        "\n",
        "But, it still won't be enough for us to try with ALL of the images.\n",
        "Therefore, we will only use 100 Images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04AxZje-OJ2h",
        "colab_type": "code",
        "outputId": "0f201f5e-2489-460e-800d-3ade3f84032f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_dir = image_dir #[:100] # Taking the first 100 Images\n",
        "len(test_dir)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5606"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxG2YjL8TwfS",
        "colab_type": "code",
        "outputId": "70959f6b-0f8f-4e67-d511-9539f9d213fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "test_dir[:5]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00000013_005.png',\n",
              " '00000013_026.png',\n",
              " '00000017_001.png',\n",
              " '00000030_001.png',\n",
              " '00000032_001.png']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6r1XGU7cufx",
        "colab_type": "text"
      },
      "source": [
        "Creating the Datasets:\n",
        "The tf.data.Dataset API supports writing descriptive and efficient input pipelines. Dataset usage follows a common pattern:\n",
        "\n",
        "- Create a source dataset from your input data.\n",
        "- Apply dataset transformations to preprocess the data.\n",
        "- Iterate over the dataset and process the elements.\n",
        "\n",
        "Iteration happens in a streaming fashion, so the full dataset does not need to fit into memory.\n",
        "\n",
        "Sources can be from:\n",
        "- LIST, using -> from_tensor_slices\n",
        "- Files given filename, using -> list_files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTRJRTWzUJpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_from_list = tf.data.Dataset.list_files(test_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcp3itjH47hl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLVTsJwPOBGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_from_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f8bCOrydb6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for element in dataset_from_list:\n",
        "  print(element)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1d9lfRNT0kG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_of_filenames = tf.data.Dataset.from_tensor_slices(test_dir) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYqLbQviUysR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_of_filenames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxsH4ERKdkAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for element in dataset_of_filenames:\n",
        "  print(element)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GsQQIZkdrvW",
        "colab_type": "text"
      },
      "source": [
        "As we can see, whether it is made using list_files or from_tensor_slices it outputs the same dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIGHalecUzjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for f in dataset_of_filenames.take(1):\n",
        "    print(f.numpy())\n",
        "    print(f)\n",
        "    print(type(f))\n",
        "    filename_str = str(f.numpy())[2:-1]\n",
        "    print(filename_str)\n",
        "    print(type(filename_str))\n",
        "    print(type(str(f.numpy())))\n",
        "    print(image_dir[0])\n",
        "    print(filename_str == image_dir[0])\n",
        "    print(sample_labels[sample_labels['Image Index'] == filename_str].reset_index().iloc[0]['Finding Labels'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtQOSPDZU2mR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_data_without_augmentation(filename, IMAGE_SIZE): #, scores, IMAGE_SIZE):\n",
        "    '''\n",
        "    Loads the image file without any augmentation. Used for validation set.\n",
        "    Args:\n",
        "        filename: the filename from the record\n",
        "        scores: the scores from the record\n",
        "    Returns:\n",
        "        an image referred to by the filename and its scores\n",
        "    '''\n",
        "\n",
        "    image = tf.io.read_file(filename)\n",
        "    image = tf.io.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "    image = (tf.cast(image, tf.float32) - 127.5) / 127.5\n",
        "\n",
        "    return image #, label #, scores\n",
        "    \n",
        "\"\"\"\"\n",
        "    print(\"FILENAME\")\n",
        "  \n",
        "    print(str(filename))\n",
        "    print(tf.strings.as_string(filename))\n",
        "    tf.compat.v1.enable_eager_execution()\n",
        "    filename_str = str(filename.numpy())[2:-1]\n",
        "    # sample_labels['Finding Labels'].tolist()\n",
        "    label = sample_labels[sample_labels['Image Index'] == filename_str].reset_index().iloc[0]['Finding Labels']\n",
        "    #sample_labels[sample_labels['Image Index'] == str(filename)]['Finding Labels']\n",
        "    print(label)\n",
        "\n",
        "\"\"\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv9DCkuXVDmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_WIDTH = 160\n",
        "IMG_HEIGHT = 160\n",
        "IMG_SIZE = 160\n",
        "IMAGE_SIZE = 160\n",
        "SHUFFLE_BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 25 #1 #####32\n",
        "#print(\"BATCH SIZE: \"+str(BATCH_SIZE))\n",
        "IMG_HEIGHT = 160 #224\n",
        "IMG_WIDTH = 160 #224\n",
        "IMG_SIZE = 160\n",
        "image_count = len(test_dir)\n",
        "print(image_count)\n",
        "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVgoutmOefDq",
        "colab_type": "text"
      },
      "source": [
        "To actually get the Image, we need to parse every bit of the image from the image file, using the function:\n",
        "parse_data_without_augmentation on the Dataset of filename we have -> list_ds.\n",
        "\n",
        "num_parallel_calls: (Optional.) If specified, the implementation creates a threadpool, which is used to fetch inputs from cycle elements asynchronously and in parallel. The default behavior is to fetch inputs from cycle elements synchronously with no parallelism. If the value tf.data.experimental.AUTOTUNE is used, then the number of parallel calls is set dynamically based on available CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy1wOyW5VFsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_dataset = dataset_of_filenames.map(lambda x: parse_data_without_augmentation(x, IMAGE_SIZE), num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpPl7Op0VQaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_U5tKAchTqG",
        "colab_type": "text"
      },
      "source": [
        "Some things we can do to Dataset object:\n",
        "- Apply transformation\n",
        "- Concatenate\n",
        "- Enumerate (Create tuples of (index, element) with specified index starting point)\n",
        "- Filter\n",
        "\n",
        "\n",
        "Since we cannot index a TF Dataset object, we can turn the Dataset into List form using the code below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MNjpuUIhGVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_ds_list = list(image_dataset.as_numpy_iterator())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BHK3z-4hKYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_ds_list[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWZvWc-ufDuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Images\n",
        "for image in image_dataset:\n",
        "  print(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Piw3apeLnapl",
        "colab_type": "text"
      },
      "source": [
        "Splitting Dataset into Training, Testing & Validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abciUL6MR3y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total = len(sample_labels)\n",
        "print(\"Total Data To Use: \"+str(total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX4sfLhXndMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note that we only have 100 images\n",
        "train_size = int(0.7*total) #70\n",
        "test_size = int(0.15*total) #15\n",
        "val_size = int(0.15*total) #15\n",
        "print(train_size)\n",
        "print(test_size)\n",
        "print(val_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHRzCPGVndPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting Image Data\n",
        "train_img = image_dataset.take(train_size)\n",
        "test_img = image_dataset.skip(train_size)\n",
        "val_img = test_img.skip(val_size)\n",
        "test_img = test_img.take(test_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB78FAQG-pIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ectrS5gNnh7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_lab = labels[0:train_size]\n",
        "print(len(train_lab))\n",
        "test_lab = labels[train_size:(train_size+test_size)]\n",
        "print(len(test_lab))\n",
        "val_lab = labels[(train_size+test_size):]\n",
        "print(len(val_lab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqP24vDZq0vT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for img in train_img:\n",
        "  print(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYHneC_gVbX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_batch(image_batch, num_elements): #, label_batch):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(num_elements):\n",
        "      ax = plt.subplot(5,5,n+1)\n",
        "      plt.imshow(image_batch[n])\n",
        "      #plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
        "      plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY8jKjqEVtmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
        "  # This is a small dataset, only load it once, and keep it in memory.\n",
        "  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
        "  # fit in memory.\n",
        "  if cache:\n",
        "    if isinstance(cache, str):\n",
        "      ds = ds.cache(cache)\n",
        "    else:\n",
        "      ds = ds.cache()\n",
        "\n",
        "  #ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "\n",
        "  # Repeat forever\n",
        "  #ds = ds.repeat()\n",
        "\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
        "  # is training.\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZugUikKrdDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = train_size\n",
        "print(\"Train size: \"+str(BATCH_SIZE))\n",
        "train_img_batch = prepare_for_training(train_img)\n",
        "BATCH_SIZE = test_size\n",
        "print(\"Test size: \"+str(BATCH_SIZE))\n",
        "test_img_batch = prepare_for_training(test_img)\n",
        "BATCH_SIZE = val_size\n",
        "print(\"Val size: \"+str(BATCH_SIZE))\n",
        "val_img_batch = prepare_for_training(val_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0Y4ihnkrdRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for img in train_img:\n",
        "#  print(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2fVi_7ardBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for img in train_img_batch:\n",
        "#  print(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suJ51Kdss9Kg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_img_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4LMWffOs9Nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch = next(iter(train_img_batch))\n",
        "test_batch = next(iter(test_img_batch))\n",
        "val_batch = next(iter(val_img_batch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiUJURSCtNql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_batch.shape)\n",
        "print(test_batch.shape)\n",
        "print(val_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RyGt2lltNoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#show_batch(val_batch.numpy(), val_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yoHXPKskU_W",
        "colab_type": "text"
      },
      "source": [
        "## Feature Extraction Using Pre-trained MobileNetV2 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Klp9iKquBGp",
        "colab_type": "text"
      },
      "source": [
        "Often, it is better to get features using a pre-trained embedding model that have been trained with millions of images, instead of training our own embedding. We will use MobileNetV2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gscpPCeTjrNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRQIyP99nDFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(IMG_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYz4_00kjrRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24iNO74WueX_",
        "colab_type": "text"
      },
      "source": [
        "Extracting features for train, test, and validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UzfK62yudOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = base_model(train_batch)\n",
        "test_features = base_model(test_batch)\n",
        "val_features = base_model(val_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBOq2VJpudXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_features.shape)\n",
        "print(test_features.shape)\n",
        "print(val_features.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nan5xySsu67v",
        "colab_type": "text"
      },
      "source": [
        "We need to convert the numpy version of these features, to Input Tensors, before inputting it to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUXPZ4tJudcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fnp = features numpy\n",
        "train_fnp = train_features.numpy()\n",
        "test_fnp = test_features.numpy()\n",
        "val_fnp = val_features.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMRY5AG2vM80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input = tf.convert_to_tensor(train_fnp, dtype=tf.float32)\n",
        "test_input = tf.convert_to_tensor(test_fnp, dtype=tf.float32)\n",
        "val_input = tf.convert_to_tensor(val_fnp, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWBz5tY2vNAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_input.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWIm2Ef6vr6X",
        "colab_type": "text"
      },
      "source": [
        "Another Way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ono6Qxyv_y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1tPxmKtvM6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch_ave = global_average_layer(train_features)\n",
        "print(train_batch_ave.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtA3AjXBvf0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_batch_ave = global_average_layer(test_features)\n",
        "print(test_batch_ave.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4Dy8v-GvfyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_batch_ave = global_average_layer(val_features)\n",
        "print(val_batch_ave.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfvaD6v7weVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_layer = tf.keras.layers.Dense(256) #(2) #256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bp4bkRCvfvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pred_batch = prediction_layer(train_batch_ave)\n",
        "print(train_pred_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5tHys2Rvftc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred_batch = prediction_layer(test_batch_ave)\n",
        "print(test_pred_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5wSbVSmwZjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_pred_batch = prediction_layer(val_batch_ave)\n",
        "print(val_pred_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr1-6Zq1wrYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input = train_pred_batch.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ewbCxk0w0sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iG7zDCt2PD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_input = test_pred_batch.numpy()\n",
        "test_input.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YgzJTDy2PA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_input = val_pred_batch.numpy()\n",
        "val_input.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vNdisT7SvGi",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing the Labels:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53Co875ZyUum",
        "colab_type": "text"
      },
      "source": [
        "Since the labels are texts, we need to create an embedding or number / vector representations from it. \n",
        "\n",
        "We will use:\n",
        "- LabelEncoder -> assigning integer 0 to number of unique categorical variable to each categorical variable. \n",
        "- OneHotEncoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56TclPcxpgc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_of_labels = len(labels)\n",
        "print(num_of_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PCKrZJrotgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_labels = sample_labels['Finding Labels'].unique().tolist()\n",
        "print(unique_labels[:5])\n",
        "num_of_unique = len(unique_labels)\n",
        "num_of_unique"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBT4kc5soteW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuZ1XkiKqoue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtBTb1DCzKeQ",
        "colab_type": "text"
      },
      "source": [
        "Creating the Label Encoder object from ALL of our Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3xqDMMcqozn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = preprocessing.LabelEncoder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylwIEJloqoxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le.fit(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e21jSUWVzQcS",
        "colab_type": "text"
      },
      "source": [
        "Encode train, test, and validation labels with Integer Values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQg57mCxrVCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_label_value = le.transform(train_lab)\n",
        "test_label_value = le.transform(test_lab)\n",
        "val_label_value = le.transform(val_lab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA2ZCXogv_Y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train_lab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Rmuimmuzmib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_to_value = pd.DataFrame(data=train_lab[:10], columns=['Original Label'])\n",
        "label_to_value['Label Value'] = train_label_value[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHg01VjRE69f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_labels_value = le.transform(labels)\n",
        "len(all_labels_value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpZsyrp10Ikp",
        "colab_type": "text"
      },
      "source": [
        "Below is the Example of Encoding Validation Label to their label values. \n",
        "\n",
        "Notice that all 'No Finding' becomes the value 24"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5f3lXpbzf3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_to_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHH-OL5NrVAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_one_hot = tf.one_hot(train_label_value, num_of_unique, on_value=1, off_value=0)\n",
        "test_one_hot = tf.one_hot(test_label_value, num_of_unique, on_value=1, off_value=0)\n",
        "val_one_hot = tf.one_hot(val_label_value, num_of_unique, on_value=1, off_value=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itZPFjSvFIEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_labels_one_hot = tf.one_hot(all_labels_value, num_of_unique, on_value=1, off_value=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHcujyb83Vj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_to_value['One Hot'] = train_one_hot[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51PlhNX20lEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_to_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-avbBVwFZx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_labels_df = pd.DataFrame(data=labels, columns=['Label'])\n",
        "all_labels_df['Value'] = all_labels_value\n",
        "all_labels_df['One Hot'] = all_labels_one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3sf1VGaFn8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_labels_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTlXOVU40wYj",
        "colab_type": "text"
      },
      "source": [
        "# Creating the CT Scan Image Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUGxM2gNqZuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1xo0TKB1AZM",
        "colab_type": "text"
      },
      "source": [
        "Additional Metrics Functions on top of Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC33eO9lgZtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n",
        "        return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "        true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
        "        return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+tf.keras.backend.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUqJtmMa2tlQ",
        "colab_type": "text"
      },
      "source": [
        "Creating the Model TRIAL #1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X42Qg0vWkXL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1 = keras.Sequential([\n",
        "    keras.Input(shape=(256)), \n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(num_of_unique, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_fV_y1hkv4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A9NqZqXkXO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy', precision_m, recall_m, f1_m])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IAI2T_T3RLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model_1.fit(train_input, train_one_hot, epochs=25, validation_data = (val_input, val_one_hot))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-DSpattUdMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2 = keras.Sequential([\n",
        "    keras.Input(shape=(256)),     \n",
        "    keras.layers.Dense(500, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.45)),\n",
        "    keras.layers.Dense(320, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.11)),     \n",
        "    keras.layers.Dense(300,kernel_regularizer=tf.keras.regularizers.l2(0.07)),     \n",
        "    keras.layers.Dropout(rate=0.001),\n",
        "    keras.layers.Dense(180),    \n",
        "    #keras.layers.Dense(10, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.07)),                 \n",
        "\n",
        "    keras.layers.Dense(num_of_unique, activation='softmax')\n",
        "])\n",
        "\n",
        "model_2.summary()\n",
        "\n",
        "model_2.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), metrics=['accuracy', precision_m, recall_m, f1_m])\n",
        "\n",
        "#history = model_2.fit(train_input, train_one_hot, epochs=25, validation_data = (val_input, val_one_hot)) # epochs=300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUIZhEezYc6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using Early Stopping:\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llmuWVfFbpjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using Early Stopping:\n",
        "callback_2 = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u3ZzzV1bZwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model_2.fit(train_input, train_one_hot, epochs=25, callbacks=[callback_2], validation_data = (val_input, val_one_hot)) # epochs=300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXTJUzo8Xhkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_3 = keras.Sequential([\n",
        "    keras.Input(shape=(256)), \n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(rate=0.7),\n",
        "    keras.layers.Dense(num_of_unique, activation='softmax'),\n",
        "])\n",
        "\n",
        "model_3.summary()\n",
        "model_3.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy', precision_m, recall_m, f1_m])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1vmyQOMXzPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_3 = model_3.fit(train_input, train_one_hot, epochs=25, validation_data = (val_input, val_one_hot))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTfza9gRZdAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_4 = keras.Sequential([\n",
        "    keras.Input(shape=(256)), \n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(rate=0.7),\n",
        "    keras.layers.Dense(num_of_unique, activation='softmax'),\n",
        "])\n",
        "\n",
        "model_4.summary()\n",
        "model_4.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy', precision_m, recall_m, f1_m])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z23mL5fg2Dtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_4 = model_4.fit(train_input, train_one_hot, epochs=300, callbacks=[callback], validation_data = (val_input, val_one_hot))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5v0nrvYcanM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_5 = keras.Sequential([\n",
        "    keras.Input(shape=(256)), \n",
        "    keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.25)),\n",
        "    keras.layers.Dropout(rate=0.7),\n",
        "    keras.layers.Dense(num_of_unique, activation='softmax'),\n",
        "])\n",
        "\n",
        "model_5.summary()\n",
        "model_5.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy', precision_m, recall_m, f1_m])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_aIMrCxcajp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_5 = model_5.fit(train_input, train_one_hot, epochs=300, validation_data = (val_input, val_one_hot))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjXLiDwmxUtX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#history = model_1.fit(train_input, train_one_hot, epochs=20, validation_data = (val_input, val_one_hot))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E42rHACQyJxP",
        "colab_type": "text"
      },
      "source": [
        "EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXJPkHknEn6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation = model_1.evaluate(test_input, test_one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkVd-c8RKQu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_evaluation_table(model, x_input, actual_label):\n",
        "  test_pred = model_1.predict(x_input)\n",
        "  argmarx_ = [np.argmax(pred) for pred in test_pred]\n",
        "  pred_labels = [all_labels_df[all_labels_df.Value == val].reset_index().iloc[0]['Label'] for val in argmarx_]\n",
        "  compare = pd.DataFrame(data=actual_label, columns=['Actual'])\n",
        "  compare['Predicted'] = pred_labels\n",
        "  return compare"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icJ7ijMkKsuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_eval_table = create_evaluation_table(model_1, test_input, test_lab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCzruJzzKsre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test_eval_table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vDjHrrqUI8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test_eval_table[0:50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z256ptlBVMSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_2 = model_2.evaluate(test_input, test_one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNCRnH7yCaXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_2_table = create_evaluation_table(model_2, val_input, val_lab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b3BxDeeCaTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#evaluation_2_table[0:60]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXRA7Aa6Y6tP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_3 = model_3.evaluate(test_input, test_one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2HlJjP-aC6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_4 = model_4.evaluate(test_input, test_one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A1Rb6VVdXMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_5 = model_5.evaluate(test_input, test_one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtmJ8jMIY6q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orxHH7WLLINg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_eval = model_1.evaluate(val_input, val_one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjdF7pa5LIQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_eval_table = create_evaluation_table(model_1, val_input, val_lab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLhuKXgCLILa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_eval_table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GViuIvyKLbOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_eval = model_1.evaluate(train_input, train_one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpwDVpLHLbL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_eval_table = create_evaluation_table(model_1, train_input, train_lab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxZisLQVLbJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_eval_table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEuqSm2zMH6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}